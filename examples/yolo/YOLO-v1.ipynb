{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from loss import *\n",
    "from dataset import *\n",
    "from model import *\n",
    "from model_resnetyolo import *\n",
    "from viz import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=20\n",
    "B=2\n",
    "S=7\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "epochs = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need more augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/VOCtrainval_11-May-2012.tar\n",
      "Extracting data/VOCtrainval_11-May-2012.tar to data\n",
      "Using downloaded and verified file: data/VOCtrainval_06-Nov-2007.tar\n",
      "Extracting data/VOCtrainval_06-Nov-2007.tar to data\n"
     ]
    }
   ],
   "source": [
    "# https://albumentations.ai/docs/api_reference/augmentations/transforms/\n",
    "# https://albumentations.ai/docs/api_reference/augmentations/geometric/transforms/\n",
    "# https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
    "transform_aug = A.Compose([\n",
    "    A.Resize(448, 448),\n",
    "    A.HorizontalFlip(),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0., saturation=0.2, hue=0.15),\n",
    "    A.Affine(scale=(1.0,1.2),translate_percent=(-0.2,0.2)),\n",
    "    A.Normalize(), # mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_visibility=0.3))\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(448, 448),\n",
    "    A.Normalize(), # mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='albumentations')) # format=albumentations is normalized pascal_voc.\n",
    "\n",
    "\n",
    "train_dataset=VOCDataset(root='data', image_set='train', S=S,C=C,transform=transform_aug)\n",
    "test_dataset=VOCDataset(root='data', image_set='val',  S=S,C=C,transform=transform)\n",
    "\n",
    "train_loader=DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_loader=DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Yolov1(split_size=S, num_boxes=B, num_classes=C).cuda()\n",
    "net = YOLOv1ResNet(S=S, B=B, C=C).cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "loss_fn = YoloLoss(S=S, B=B, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('backup/checkpoint_149.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    loop = tqdm(train_loader)\n",
    "    for i, (img, (boxes, labels, Iobj), index) in enumerate(loop):\n",
    "        img, boxes, labels, Iobj = img.cuda(), boxes.cuda(), labels.cuda(), Iobj.cuda()\n",
    "        out = net(img)\n",
    "        loss = loss_fn(out, (boxes, labels, Iobj))\n",
    "        train_loss+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_history['train'].append(train_loss / (i + 1))\n",
    "\n",
    "    \n",
    "    \n",
    "@torch.no_grad()\n",
    "def val_test(dataloader):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(dataloader)\n",
    "    for i, (img, (boxes, labels, Iobj), index) in enumerate(loop):\n",
    "        img, boxes, labels, Iobj = img.cuda(), boxes.cuda(), labels.cuda(), Iobj.cuda()\n",
    "        out = net(img)\n",
    "        loss = loss_fn(out, (boxes, labels, Iobj))\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / (i + 1)\n",
    "    return avg_loss\n",
    "    \n",
    "\n",
    "    \n",
    "def save():\n",
    "    global lowest_loss\n",
    "    # save checkpoint\n",
    "    \n",
    "    if epoch>50 and loss_history['val'][-1]<10 and loss_history['val'][-1] < lowest_loss:\n",
    "        torch.save(net.state_dict(), f'models/checkpoint_{str(epoch).zfill(3)}.npy')\n",
    "        lowest_loss = loss_history['val'][-1]\n",
    "\n",
    "    # save loss, error history and log\n",
    "    torch.save(loss_history, 'logs/loss_history.npy')\n",
    "    with open('logs/log.txt', 'a') as f:\n",
    "        f.write('epoch{} finished at {}. val_loss: {:.4f}\\n'.\n",
    "                format(str(epoch).zfill(3),\n",
    "                       datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\"),\n",
    "                       loss_history['val'][-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████                       | 1191/2885 [03:43<05:18,  5.32it/s]"
     ]
    }
   ],
   "source": [
    "loss_history = {'train': [], 'val': []}\n",
    "\n",
    "if os.path.exists('logs/log.txt'):\n",
    "    raise OSError('Previous training logs already exist.')\n",
    "\n",
    "lowest_loss = 100\n",
    "warmup=0\n",
    "for epoch in range(epochs):\n",
    "    if epoch < warmup:\n",
    "        optimizer.param_groups[0]['lr'] = learning_rate / 10\n",
    "    elif epoch == warmup:\n",
    "        optimizer.param_groups[0]['lr'] = learning_rate\n",
    "    \n",
    "    # train\n",
    "    train()\n",
    "    \n",
    "    # validation\n",
    "    test_loss = val_test(test_loader)\n",
    "    loss_history['val'].append(test_loss)\n",
    "    print(' - val_loss: {:.4f}\\n'.format(loss_history['val'][-1]))\n",
    "    \n",
    "    # save\n",
    "    save()\n",
    "    \n",
    "    # step scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = torch.load('logs/loss_history.npy')\n",
    "plt.plot(loss_history['train'], 'r', label='train')\n",
    "plt.plot(loss_history['val'], 'b', label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss history')\n",
    "plt.legend()\n",
    "plt.ylim([1,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import time\n",
    "# time.sleep(3)\n",
    "# subprocess.Popen(('shutdown', 'now'), stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
