{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm # progress bar\n",
    "import h5py # for loading .h5 file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../../../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=128\n",
    "nc = 3\n",
    "nz = 128 # size of the latent z vector\n",
    "ngf = 64 # relates to the depth of feature maps carried through the generator\n",
    "ndf = 64 # sets the depth of feature maps propagated through the discriminator\n",
    "epochs=60\n",
    "lr=2e-4\n",
    "beta1=0.5 # beta1 for adam. default=0.5\n",
    "d_labelSmooth=0.25 # for D, use soft label \"1-labelSmooth\" for real samples. 0.25 from imporved-GAN paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only use dataset and dataloader from pytorch\n",
    "tensors loaded using `pytorch` will be converted to `tortto` tensors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.utils import save_image\n",
    "from torch import tensor as torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeDataset(Dataset):\n",
    "    def __init__(self, fn, transform):\n",
    "        super().__init__()\n",
    "        self.fn=fn\n",
    "        self.dataset = None\n",
    "        self.transform=transform\n",
    "        with h5py.File(fn, \"r\") as file:\n",
    "            self.dataset_len=len(file['images'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.fn, 'r')[\"images\"]\n",
    "        if self.transform is not None:\n",
    "            return self.transform(self.dataset[idx])\n",
    "        return self.dataset[idx]\n",
    "\n",
    "dataset=AnimeDataset('dataset/anime_faces.h5', transform=Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "]))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batchSize, drop_last=True, shuffle=True, num_workers=os.cpu_count())\n",
    "print(f'contains {len(dataset)} images of size {tuple(dataset[0].shape)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataloading speed to make sure there is no IO bottleneck. It will take some time to speed up.\n",
    "\n",
    "If there is a `h5py objects cannot be pickled` error, delete `num_workers=4` from Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(dataloader):\n",
    "    a=i[0,0,0,0]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the rest is done in pytortto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tortto as tt\n",
    "import tortto.nn as nn\n",
    "import tortto.nn.functional as F\n",
    "import tortto.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.transConv1 = nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf * 8)\n",
    "        self.transConv2 = nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 4)\n",
    "        self.transConv3 = nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf * 2)\n",
    "        self.transConv4 = nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf)\n",
    "        # one extra layer\n",
    "        self.extra1 = nn.Conv2d(ngf, ngf, 3, 1, 1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(ngf)\n",
    "        # final layer\n",
    "        self.final = nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.transConv1(x)), 0.2, True)  # B,z,1,1->B,ngf*8,4,4\n",
    "        x = F.leaky_relu(self.bn2(self.transConv2(x)), 0.2, True)  # B,ngf*8,4,4->B,ngf*4,8,8\n",
    "        x = F.leaky_relu(self.bn3(self.transConv3(x)), 0.2, True)  # B,ngf*4,8,8->B,ngf*2,16,16\n",
    "        x = F.leaky_relu(self.bn4(self.transConv4(x)), 0.2, True)  # B,ngf*2,16,16->B,ngf,32,32\n",
    "        x = F.leaky_relu(self.bn5(self.extra1(x)), 0.2, True)  # B,ngf,32,32->B,ngf,32,32\n",
    "        x = tt.tanh(self.final(x))  # B,ngf,32,32->B,nc,64,64\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf, nc):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, True)  # B,nc,64,64->B,ndf,32,32\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2, True)  # B,ndf,32,32->B,ndf*2,16,16\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2, True)  # B,ndf*2,16,16->B,ndf*4,8,8\n",
    "        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2, True)  # B,ndf*4,8,8->B,ndf*8,4,4\n",
    "        x = self.conv5(x)\n",
    "        return x.view(-1)  # B,1,1,1->B,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G=Generator(nz, ngf, nc).cuda()\n",
    "D=Discriminator(ndf, nc).cuda()\n",
    "\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizerD = optim.Adam(D.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "optimizerG = optim.Adam(G.parameters(), lr = lr, betas = (beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('logs/log.txt'):\n",
    "    raise OSError('Previous training logs already exist.')\n",
    "\n",
    "noise = tt.randn(batchSize, nz, 1, 1).cuda()\n",
    "fixed_noise = tt.randn(64, nz, 1, 1).cuda()\n",
    "label = tt.zeros(batchSize).cuda()\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader)\n",
    "    for i, real in enumerate(loop, 0):\n",
    "        \n",
    "        real = tt.tensor(real.numpy()).cuda()\n",
    "        \n",
    "        # (1) Update D network\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # train with real\n",
    "        output = D(real)\n",
    "        nn.init.constant_(label, 1 - d_labelSmooth)\n",
    "        lossD_real = criterion(output, label)\n",
    "        lossD_real.backward()\n",
    "\n",
    "        # train with fake\n",
    "        nn.init.normal_(noise)\n",
    "        fake = G(noise)\n",
    "        output = D(fake.detach())\n",
    "        nn.init.zeros_(label)\n",
    "        lossD_fake = criterion(output, label)\n",
    "        lossD_fake.backward()\n",
    "        \n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update G network\n",
    "        optimizerG.zero_grad()\n",
    "        output = D(fake)\n",
    "        nn.init.ones_(label) # fake labels are real for generator cost\n",
    "        lossG = criterion(output, label)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "    with tt.no_grad():\n",
    "        fake = G(fixed_noise)\n",
    "        save_image(torch_tensor(fake.detach().cpu().numpy()*0.5+0.5), \n",
    "                   f'results/fake_samples_epoch_{str(epoch).zfill(3)}.png', nrow=8)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'generator': G.state_dict(),\n",
    "        'discriminator': D.state_dict()\n",
    "            }\n",
    "    tt.save(checkpoint, f'models/checkpoint_{str(epoch).zfill(3)}.npy')\n",
    "    with open('logs/log.txt','a') as f:\n",
    "        f.write(f'epoch{str(epoch).zfill(3)} finished at {datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(to_plot, num):\n",
    "    fig,axs=plt.subplots(len(to_plot),num,figsize=(2*len(to_plot)*1.1,len(to_plot)*1.1))\n",
    "    i=0\n",
    "    for start,stop in to_plot:\n",
    "        step=(stop-start)/(num-1)\n",
    "        z=tt.randn(num, nz, 1, 1)\n",
    "        for n in range(num):\n",
    "            z[n,:,:,:] = start + n*step\n",
    "        with tt.no_grad():\n",
    "            y = tt.moveaxis(G(z)*0.5+0.5, 1, -1).numpy()\n",
    "        for j in range(num):\n",
    "            axs[i,j].imshow(y[j])\n",
    "            axs[i,j].axis('off')\n",
    "        i+=1\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to set to eval mode, otherwise it's not independent on batch dimension due to batch norm.\n",
    "# for example, if you create a person with gray hair using a single noise vector,\n",
    "# that person will probably have yellow hair, if you put that single noise vector into a batch of noise vectors.\n",
    "G.eval()\n",
    "G=G.cpu()\n",
    "checkpoint = tt.load('models/checkpoint_059.npy')\n",
    "G.load_state_dict(checkpoint['generator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot 64 random generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI enlarge: https://bigjpg.com/\n",
    "tt.manual_seed(42)\n",
    "size=8\n",
    "noise = tt.randn(size*size, nz, 1, 1)\n",
    "# nn.init.normal_(noise,0,0.8)\n",
    "with tt.no_grad():\n",
    "    fake = G(noise)\n",
    "    image = tt.moveaxis(fake*0.5+0.5, 1, -1).numpy()\n",
    "fig,axs=plt.subplots(size,size,figsize=(size+1,size+1))\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        axs[i,j].imshow(image[size*i+j])\n",
    "        axs[i,j].axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot transient of selected images\n",
    "results will differ on different machines. Need to manually select images that look good by running the above cell. Don't forget to try different random seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot=[]\n",
    "\n",
    "#\n",
    "tt.manual_seed(42)\n",
    "noise = tt.randn(64, nz, 1, 1)\n",
    "to_plot.extend([(noise[-22], noise[-37]),(noise[34], noise[38]),(noise[-12], noise[35])])\n",
    "\n",
    "#\n",
    "nn.init.normal_(noise,0,0.8)\n",
    "to_plot.extend([(noise[-8], noise[-22])])\n",
    "\n",
    "#\n",
    "tt.manual_seed(10)\n",
    "noise = tt.randn(64, nz, 1, 1)\n",
    "to_plot.extend([(noise[12], noise[16]),(noise[-12], noise[-33])])\n",
    "\n",
    "# plot all selected images\n",
    "transition(to_plot, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
